# ğŸ™ï¸ Real-Time Voice AI Assistant

A sophisticated real-time voice conversation system that combines **speech-to-text**, **AI agents**, and **text-to-speech** for seamless voice interactions. Built with FastAPI, OpenAI Whisper, AutoGen, and Edge TTS.

## âœ¨ Features

### ğŸ¯ **Core Capabilities**
- **Real-time Speech Recognition** - Live audio transcription using OpenAI Whisper
- **Intelligent AI Agents** - Multi-agent system with specialized roles (math, stories, general)
- **Natural Voice Synthesis** - High-quality text-to-speech with Microsoft Edge TTS
- **Continuous Conversation** - Automatic listening restart after responses
- **Web-based Interface** - Clean, responsive browser interface

### ğŸ¤– **AI Agent System**
- **Manager Agent** - Routes queries to appropriate specialists
- **Math Agent** - Handles mathematical questions with kid-friendly explanations
- **Story Agent** - Creates engaging short stories for children
- **General Agent** - Manages greetings, casual conversation, and general queries
- **Fallback System** - Simple backup agent when AutoGen is unavailable

### ğŸ”Š **Audio Processing**
- **Low-latency Streaming** - Real-time audio processing with WebSocket
- **Multiple Audio Formats** - WebM, Opus, WAV support
- **Voice Activity Detection** - Intelligent speech detection
- **Audio Quality Control** - Configurable chunk sizes and quality settings

## ğŸš€ Quick Start

### Prerequisites
- **Python 3.8+**
- **FFmpeg** (for audio processing)
- **Microphone access** in your browser

### Installation

1. **Clone the repository**
```bash
git clone <repository-url>
cd whisper_streaming_web
```

2. **Create virtual environment**
```bash
python -m venv .venv
# Windows
.venv\Scripts\activate
# Linux/Mac
source .venv/bin/activate
```

3. **Install dependencies**
```bash
pip install -r requirements.txt
```

4. **Set up environment variables** (optional)
Create a `.env` file:
```env
# For AutoGen AI agents (optional)
GEMINI_API_KEY=your_gemini_api_key_here
# OR
OPENAI_API_KEY=your_openai_api_key_here
LLM_MODEL=gemini-1.5-flash
```

5. **Run the server**
```bash
python whisper_fastapi_online_server.py
```

6. **Open your browser**
Navigate to `http://localhost:8000`

## ğŸ® Usage

### Basic Operation
1. **Click the microphone button** ğŸ™ï¸ to start conversation
2. **Speak your question** clearly
3. **Listen to the AI response** with automatic voice synthesis
4. **Continue the conversation** - the system automatically restarts listening

### Example Interactions
- **Math**: "What is 2 plus 2?"
- **Stories**: "Tell me a story about a lion"
- **General**: "Hello, how are you?"

### Configuration Options
- **Chunk Size**: Adjust audio processing intervals (500ms - 5000ms)
- **WebSocket URL**: Change server endpoint if needed
- **Voice Selection**: Multiple high-quality neural voices available

## ğŸ—ï¸ Architecture

### System Components
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Web Browser   â”‚â—„â”€â”€â–ºâ”‚   FastAPI Server â”‚â—„â”€â”€â–ºâ”‚   AI Agents     â”‚
â”‚                 â”‚    â”‚                  â”‚    â”‚                 â”‚
â”‚ â€¢ Microphone    â”‚    â”‚ â€¢ WebSocket      â”‚    â”‚ â€¢ AutoGen       â”‚
â”‚ â€¢ Audio Capture â”‚    â”‚ â€¢ Audio Pipeline â”‚    â”‚ â€¢ Gemini/OpenAI â”‚
â”‚ â€¢ TTS Playback  â”‚    â”‚ â€¢ Whisper STT    â”‚    â”‚ â€¢ Fallback      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Audio Pipeline
```
Microphone â†’ WebM/Opus â†’ FFmpeg â†’ PCM â†’ Whisper â†’ Text â†’ AI Agent â†’ TTS â†’ Audio
```

### File Structure
```
whisper_streaming_web/
â”œâ”€â”€ whisper_fastapi_online_server.py  # Main server
â”œâ”€â”€ requirements.txt                  # Dependencies
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ AI_agent/
â”‚   â”‚   â””â”€â”€ ai_agent_runtime.py      # AutoGen agent system
â”‚   â”œâ”€â”€ web/
â”‚   â”‚   â””â”€â”€ live_transcription.html  # Frontend interface
â”‚   â”œâ”€â”€ whisper_streaming/           # Whisper integration
â”‚   â””â”€â”€ diarization/                 # Speaker identification
â””â”€â”€ README.md
```

## âš™ï¸ Configuration

### Command Line Options
```bash
python whisper_fastapi_online_server.py --help
```

Key parameters:
- `--host`: Server host (default: localhost)
- `--port`: Server port (default: 8000)
- `--model`: Whisper model size (tiny.en, base, small, medium, large)
- `--min-chunk-size`: Audio chunk duration in seconds
- `--language`: Source language (en, es, fr, etc.)

### Environment Variables
- `GEMINI_API_KEY`: Google Gemini API key for AI agents
- `OPENAI_API_KEY`: OpenAI API key (alternative to Gemini)
- `LLM_MODEL`: Model name (default: gemini-1.5-flash)

## ğŸ”§ Advanced Features

### Multi-Agent System
The AI system uses AutoGen's multi-agent framework:
- **Intelligent Routing**: Manager agent analyzes queries and routes to specialists
- **Specialized Responses**: Each agent optimized for specific tasks
- **JSON Structured Output**: Consistent response formatting
- **Graceful Fallbacks**: Simple backup responses when needed

### Audio Quality Options
- **Multiple TTS Voices**: High-quality neural voices
- **Adaptive Chunk Sizes**: Balance between latency and accuracy
- **Voice Activity Detection**: Smart speech detection
- **Audio Format Support**: WebM, Opus, WAV compatibility

### Real-time Processing
- **WebSocket Streaming**: Low-latency bidirectional communication
- **Concurrent Processing**: Parallel audio and AI processing
- **State Management**: Conversation flow control
- **Error Recovery**: Robust error handling and recovery

## ğŸ› ï¸ Development

### Key Dependencies
- **FastAPI**: Web framework and WebSocket support
- **OpenAI Whisper**: Speech recognition
- **AutoGen**: Multi-agent AI framework
- **Edge TTS**: Text-to-speech synthesis
- **FFmpeg**: Audio processing
- **PyTorch**: Machine learning backend

### Adding New Agents
1. Define agent in `src/AI_agent/ai_agent_runtime.py`
2. Add to manager's handoff list
3. Implement specialized system message
4. Test with conversation flow

### Customizing TTS
- Modify voice selection in `_edge_voices` list
- Adjust audio quality parameters
- Add new TTS backends as needed

## ğŸ› Troubleshooting

### Common Issues
1. **Microphone not working**: Check browser permissions
2. **FFmpeg errors**: Ensure FFmpeg is installed and in PATH
3. **AI agent timeouts**: Check API keys and network connectivity
4. **Audio quality issues**: Adjust chunk size and audio format

### Debug Mode
Enable detailed logging by checking browser console and server output.

## ğŸ“„ License

This project is open source. Please check the license file for details.

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit issues and pull requests.

---

**Built with â¤ï¸ for seamless voice AI interactions**
